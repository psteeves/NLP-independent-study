{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Classification using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by Patrick Steeves as part of Independent Study with Professor Kanungo<br>\n",
    "George Washington University 12/23/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be found at https://www.kaggle.com/uciml/news-aggregator-dataset <br>\n",
    "The data contains 400,000 headlines from news stories in 2014 in one of 4 categories: health, business, science and tech, entertainment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import nececssary modules, set directory path, and import titles data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import time\n",
    "from collections import Counter\n",
    "import re\n",
    "import math\n",
    "\n",
    "path = \"C:\\\\Users\\\\patri\\\\Documents\\\\GW\\\\2017Fall\\\\Independent Study\\\\Simple project\\\\\"\n",
    "titles = pd.read_csv(path+\"Data\\\\news_headlines.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titles have the following categories: <br>\n",
    "b - business <br>\n",
    "e - entertainment <br>\n",
    "t - science and technology <br>\n",
    "m - health <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1  Fed official says weak data caused by weather,...   \n",
       "1   2  Fed's Charles Plosser sees high bar for change...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "\n",
       "  CATEGORY                          STORY          HOSTNAME      TIMESTAMP  \n",
       "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM   www.latimes.com  1394470370698  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.livemint.com  1394470371207  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean titles. Drop unnecessary columns, remove punctuation and stopwords, and stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanWords(df, path = 0):\n",
    "    # If path variable is specified, create CSV file with cleaned titles\n",
    "    headlines = df.drop(['URL','STORY','TIMESTAMP','HOSTNAME','ID'], axis=1)\n",
    "\n",
    "    start = time.time()\n",
    "    stopped_words = []\n",
    "    i = 0\n",
    "    print(\"Started cleaning headlines...\")\n",
    "    stemmer = PorterStemmer()\n",
    "    for row in df['TITLE']:\n",
    "        cleaned_title = re.sub('[^a-zA-Z]+',' ', row).lower()    # Only keep alphabetical characters\n",
    "        words = [stemmer.stem(word) for word in cleaned_title.split() if word not in stopwords.words('english')]   # Stem and filter words\n",
    "        stopped_words.append(','.join(words))\n",
    "        i+=1\n",
    "        if i % 30000 == 0:\n",
    "            print(\"Done cleaning {} headlines\".format(i))   # Update user on progress\n",
    "\n",
    "    headlines['STOPPED_WORDS'] = stopped_words\n",
    "    if path:\n",
    "        headlines.to_csv(path+\"Data\\\\headline_words.csv\",index=False)\n",
    "    print(\"Took {:07.2f} seconds to create CSV file with filtered words\".format(time.time()-start))\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data has not been cleaned already, import CSV of cleaned headlines. If CSV has not yet been created, clean headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if locals().get('headlines') == None:\n",
    "    if \"headline_words.csv\" in os.listdir(path+\"Data\"):\n",
    "        headlines = pd.read_csv(path + \"Data\\\\headline_words.csv\", encoding = \"latin1\", keep_default_na = False)\n",
    "    else:\n",
    "        headlines = mod.cleanWords(titles, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STOPPED_WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>fed,offici,say,weak,data,caus,weather,slow,taper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>fed,charl,plosser,see,high,bar,chang,pace,taper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>us,open,stock,fall,fed,offici,hint,acceler,taper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE          PUBLISHER  \\\n",
       "0  Fed official says weak data caused by weather,...  Los Angeles Times   \n",
       "1  Fed's Charles Plosser sees high bar for change...           Livemint   \n",
       "2  US open: Stocks fall after Fed official hints ...       IFA Magazine   \n",
       "\n",
       "  CATEGORY                                     STOPPED_WORDS  \n",
       "0        b  fed,offici,say,weak,data,caus,weather,slow,taper  \n",
       "1        b   fed,charl,plosser,see,high,bar,chang,pace,taper  \n",
       "2        b  us,open,stock,fall,fed,offici,hint,acceler,taper  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines.iloc[:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a PDF of words, calculate P(cat | word), modified using Laplacian Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getProb(pdf, words_in_cat, cat, word, total_words):\n",
    "    # words_in_cat is number of unique words in category, total_words is total number of words in all categories\n",
    "    laplace_smooth = 1\n",
    "    prob = pdf.get(word)\n",
    "    return ((0 if prob is None else prob) + laplace_smooth) / (words_in_cat + laplace_smooth*total_words)    # If word is not in PDF of cat, first term in expression is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Build class for NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NBClassifier:\n",
    "    \"\"\"\n",
    "    Naive Bayes Classifier. Given Pandas Series of titles and categories, trains PDF to perform classification on article categories.\n",
    "    \"\"\"\n",
    "    def __init__(self, titles, categories, train_split = 1):\n",
    "        self.data = pd.concat([titles,categories], axis=1)                               # Dataframe of cleaned titles and cats\n",
    "        train_idx = np.random.rand(len(self.data)) < train_split                         # Training data rows\n",
    "        self.train_data = self.data.loc[train_idx,:].copy()                              # Train data\n",
    "        self.test_data = self.data.loc[~train_idx,:].copy()                              # Test data\n",
    "        self.all_words = []\n",
    "        self.pdf = {}\n",
    "        self.words_per_cat = {}\n",
    "        \n",
    "        i = 0\n",
    "        for row in titles:                                                               # List of all words used in titles\n",
    "            self.all_words += row.split(',')\n",
    "            i += 1\n",
    "            if i % 50000 == 0:\n",
    "                print(\"Done reading {} headlines\".format(i))\n",
    "\n",
    "        self.total_words = len(self.all_words)                                          # Number of total words used\n",
    "        self.word_count = dict(Counter(self.all_words))                                 # Word count\n",
    "        self.common_words = {w:c for w,c in self.word_count.items() if c > 4}           # Only keep words that appear at least 5 times\n",
    "        self.common_words.pop('')\n",
    "        self.unique_words = self.common_words.keys()                                    # List of unique words\n",
    "        self.categories = set(categories)                                               # Set possible categories\n",
    "        self.train_accuracy = None\n",
    "        self.test_accuracy = None\n",
    "        self.trained = False                                                            # True if PDF has already been trained on data\n",
    "        self.misclassified = None                                                       # Misclassified titles from test set\n",
    "\n",
    "    def trainPDF(self):\n",
    "        \"\"\"\n",
    "        Train PDF on data. Creates dictionary of categories, which each contains dictionary of word counts\n",
    "        \"\"\"\n",
    "        i = 1\n",
    "        for cat in self.categories:\n",
    "            print(\"Creating PDf for category {}/{}\".format(i,len(self.categories)))\n",
    "            indexed = self.train_data.loc[lambda df: df.iloc[:,1] == cat,:]             # Subset of training titles corresponding to category\n",
    "            self.words_per_cat[cat] = 0\n",
    "            self.pdf[cat]={}\n",
    "            for row in indexed.iloc[:,0]:\n",
    "                title_words = row.split(',')\n",
    "                self.words_per_cat[cat] += len(title_words)                             # Iteratively count number of words in titles for category\n",
    "                for word in title_words:\n",
    "                    if self.pdf[cat].get(word):\n",
    "                        self.pdf[cat][word] += 1                                        # For every word in title, iteratively update word count for category\n",
    "                    else:\n",
    "                        self.pdf[cat][word] = 1\n",
    "            i+=1\n",
    "        self.trained = True                                                             # Set trained flag to true\n",
    "\n",
    "    def predictCat(self, title, already_stopped = False):\n",
    "        \"\"\"\n",
    "        Given a title, predict category of article. Assumes that title is not already cleaned. Returns dictionary of category probabilities for title.\n",
    "        \"\"\"\n",
    "        if already_stopped:\n",
    "            words = [word for word in title.split(',')]\n",
    "        else:\n",
    "            stemmer = PorterStemmer()\n",
    "            cleaned_title = re.sub('[^a-zA-Z]+',' ', title).lower()\n",
    "            words = [stemmer.stem(word) for word in cleaned_title.split() if word not in stopwords.words('english')]\n",
    "        preds = {}\n",
    "        for cat in self.categories:\n",
    "            preds[cat] = 0\n",
    "            for word in words:\n",
    "                preds[cat] += math.log(getProb(self.pdf[cat], self.words_per_cat[cat], cat, word, self.total_words))\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def runClassifier(self):\n",
    "        \"\"\"\n",
    "        Using trained Classifier, predict training and testing data.\n",
    "        \"\"\"\n",
    "        if not self.trained:\n",
    "            print(\"You must train the classifier first\")\n",
    "            return\n",
    "        self.train_data.loc[:,'PREDICTED'] = ''                                         # Add column for predicted category\n",
    "        self.test_data.loc[:,'PREDICTED'] = ''\n",
    "        print(\"Predicting train data\")\n",
    "        start_min = time.time()        \n",
    "        for idx, row in self.train_data.iterrows():\n",
    "            tr_predictions = self.predictCat(row.iloc[0], True)                         # Probability of each category for given title\n",
    "            self.train_data.loc[idx,'PREDICTED'] = max(tr_predictions, key = tr_predictions.get)   # Predict title using max prob\n",
    "            if time.time() - start_min > 30:\n",
    "                print(\"{:2.1f}% Done with training data\".format(100*idx/self.train_data.index[-1]))\n",
    "                start_min = time.time()\n",
    "\n",
    "        print(\"Predicting test data\")\n",
    "        start_min = time.time()\n",
    "        for idx, row in self.test_data.iterrows():\n",
    "            te_predictions = self.predictCat(row.iloc[0], True)\n",
    "            self.test_data.loc[idx,'PREDICTED'] = max(te_predictions, key = te_predictions.get)\n",
    "            if time.time() - start_min > 30:\n",
    "                print(\"{:2.1f}% Done with testing data\".format(100*idx/self.train_data.index[-1]))\n",
    "                start_min = time.time()\n",
    "\n",
    "        self.train_accuracy = sum(self.train_data.PREDICTED == self.train_data.CATEGORY) / len(self.train_data)   # Update training accuracy\n",
    "        if len(self.test_data > 0):\n",
    "            self.test_accuracy = sum(self.test_data.PREDICTED == self.test_data.CATEGORY) / len(self.test_data)   # Update testing accuracy\n",
    "        \n",
    "        if len(self.test_data > 0):                                                                               # Get misclassified titles\n",
    "            self.misclassified = self.test_data.loc[self.test_data['PREDICTED'] != self.test_data.iloc[:,1]]\n",
    "        else:\n",
    "            self.misclassified = self.train_data.loc[self.train_data['PREDICTED'] != self.train_data.iloc[:,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading 50000 headlines\n",
      "Done reading 100000 headlines\n",
      "Done reading 150000 headlines\n",
      "Done reading 200000 headlines\n",
      "Done reading 250000 headlines\n",
      "Done reading 300000 headlines\n",
      "Done reading 350000 headlines\n",
      "Done reading 400000 headlines\n"
     ]
    }
   ],
   "source": [
    "classifier = NBClassifier(headlines['STOPPED_WORDS'], headlines['CATEGORY'], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PDf for category 1/4\n",
      "Creating PDf for category 2/4\n",
      "Creating PDf for category 3/4\n",
      "Creating PDf for category 4/4\n"
     ]
    }
   ],
   "source": [
    "classifier.trainPDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting train data\n",
      "12.6% Done with training data\n",
      "26.7% Done with training data\n",
      "41.3% Done with training data\n",
      "55.7% Done with training data\n",
      "70.8% Done with training data\n",
      "85.7% Done with training data\n",
      "Predicting test data\n"
     ]
    }
   ],
   "source": [
    "classifier.runClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916254471842\n",
      "0.912415965399\n"
     ]
    }
   ],
   "source": [
    "print(classifier.train_accuracy)\n",
    "print(classifier.test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show examples of misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOPPED_WORDS</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>PREDICTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>predict,new,week</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>window,westminst</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>china,learn,rescu,lame,duck</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>death,star,orion,wreak,havoc,planet,even,develop</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>news</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>mt,gox,file,us,bankruptci</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>bitcoin,exchang,mt,gox,file,u,bankruptci,death...</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>presid,obama,introduc,cosmo,debut,episod</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>itun,festiv,app,readi,ahead,sxsw,concert,seri</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>ohio,ga,price,steadi,start,work,week</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          STOPPED_WORDS CATEGORY PREDICTED\n",
       "167                                    predict,new,week        b         e\n",
       "655                                    window,westminst        b         t\n",
       "840                         china,learn,rescu,lame,duck        b         e\n",
       "1117   death,star,orion,wreak,havoc,planet,even,develop        t         e\n",
       "1163                                               news        t         e\n",
       "1176                          mt,gox,file,us,bankruptci        t         b\n",
       "1186  bitcoin,exchang,mt,gox,file,u,bankruptci,death...        t         b\n",
       "1585           presid,obama,introduc,cosmo,debut,episod        t         e\n",
       "1849      itun,festiv,app,readi,ahead,sxsw,concert,seri        t         e\n",
       "1856               ohio,ga,price,steadi,start,work,week        t         b"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.misclassified.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STOPPED_WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>3 Predictions for the New Week</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>b</td>\n",
       "      <td>predict,new,week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>Window on Westminster</td>\n",
       "      <td>Rudaw</td>\n",
       "      <td>b</td>\n",
       "      <td>window,westminst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>China learns not to rescue its lame ducks</td>\n",
       "      <td>Director of Finance online</td>\n",
       "      <td>b</td>\n",
       "      <td>china,learn,rescu,lame,duck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>'Death stars' in Orion wreak havoc on planets ...</td>\n",
       "      <td>Science Recorder</td>\n",
       "      <td>t</td>\n",
       "      <td>death,star,orion,wreak,havoc,planet,even,develop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>What's News</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>t</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Mt Gox files US bankruptcy</td>\n",
       "      <td>Stuff.co.nz</td>\n",
       "      <td>t</td>\n",
       "      <td>mt,gox,file,us,bankruptci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>Bitcoin Exchange Mt. Gox Files for U.S. Bankru...</td>\n",
       "      <td>Wired</td>\n",
       "      <td>t</td>\n",
       "      <td>bitcoin,exchang,mt,gox,file,u,bankruptci,death...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>President Obama Introduces 'Cosmos' Debut Episode</td>\n",
       "      <td>Newsmax.com</td>\n",
       "      <td>t</td>\n",
       "      <td>presid,obama,introduc,cosmo,debut,episod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>iTunes Festival apps ready ahead of SXSW conce...</td>\n",
       "      <td>iSource</td>\n",
       "      <td>t</td>\n",
       "      <td>itun,festiv,app,readi,ahead,sxsw,concert,seri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>Ohio gas prices steady to start work week</td>\n",
       "      <td>Huntington Herald Dispatch</td>\n",
       "      <td>t</td>\n",
       "      <td>ohio,ga,price,steadi,start,work,week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TITLE  \\\n",
       "167                      3 Predictions for the New Week   \n",
       "655                               Window on Westminster   \n",
       "840           China learns not to rescue its lame ducks   \n",
       "1117  'Death stars' in Orion wreak havoc on planets ...   \n",
       "1163                                       What's News   \n",
       "1176                         Mt Gox files US bankruptcy   \n",
       "1186  Bitcoin Exchange Mt. Gox Files for U.S. Bankru...   \n",
       "1585  President Obama Introduces 'Cosmos' Debut Episode   \n",
       "1849  iTunes Festival apps ready ahead of SXSW conce...   \n",
       "1856          Ohio gas prices steady to start work week   \n",
       "\n",
       "                       PUBLISHER CATEGORY  \\\n",
       "167                  Motley Fool        b   \n",
       "655                        Rudaw        b   \n",
       "840   Director of Finance online        b   \n",
       "1117            Science Recorder        t   \n",
       "1163         Wall Street Journal        t   \n",
       "1176                 Stuff.co.nz        t   \n",
       "1186                       Wired        t   \n",
       "1585                 Newsmax.com        t   \n",
       "1849                     iSource        t   \n",
       "1856  Huntington Herald Dispatch        t   \n",
       "\n",
       "                                          STOPPED_WORDS  \n",
       "167                                    predict,new,week  \n",
       "655                                    window,westminst  \n",
       "840                         china,learn,rescu,lame,duck  \n",
       "1117   death,star,orion,wreak,havoc,planet,even,develop  \n",
       "1163                                               news  \n",
       "1176                          mt,gox,file,us,bankruptci  \n",
       "1186  bitcoin,exchang,mt,gox,file,u,bankruptci,death...  \n",
       "1585           presid,obama,introduc,cosmo,debut,episod  \n",
       "1849      itun,festiv,app,readi,ahead,sxsw,concert,seri  \n",
       "1856               ohio,ga,price,steadi,start,work,week  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines.iloc[[167,655,840,1117,1163,1176,1186,1585,1849,1856],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if classifier also works on random title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': -41.36362907626666,\n",
       " 'e': -52.543570547479376,\n",
       " 'm': -54.80713540820604,\n",
       " 't': -44.5483659972368}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predictCat('Apple posts higher returns this quarter')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
