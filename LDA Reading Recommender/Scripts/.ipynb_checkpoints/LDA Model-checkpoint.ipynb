{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling of American News Articles Using LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by Patrick Steeves for Independent Study with Professor Kanungo <br>\n",
    "George Washington University, 12/23/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import notebook Module.ipynb, which contains functions to import and clean the data, add features, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run Module.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br> <br> Data import and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have is collected from Kaggle at https://www.kaggle.com/snapcrack/all-the-news <br>\n",
    "It contains 143,000 articles and is available for download as 3 files: articles1.csv, articles2.csv, articles3.csv <br><br> The data was split into smaller subsets and is downloaded here from GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all non alphabetical characters, tokenize words, lemmatize words, and filter out stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import news articles from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing and unzipping file 0...\n",
      "Importing and unzipping file 1...\n",
      "Importing and unzipping file 2...\n",
      "Importing and unzipping file 3...\n",
      "Importing and unzipping file 4...\n",
      "Importing and unzipping file 5...\n",
      "Importing and unzipping file 6...\n",
      "Importing and unzipping file 7...\n",
      "Computing word counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 14605.,  29648.,  27947.,  23224.,  16881.,  10264.,   6836.,\n",
       "          4108.,   2560.,   1608.]),\n",
       " array([   0,  200,  400,  600,  800, 1000, 1200, 1400, 1600, 1800, 2000]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = importData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is only concerned with recommending articles of similar and average length. It does not wish to recommend articles of less than 200 words, or over 700 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(data.word_count, bins=[b for b in range(0,2001, 200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cleaning...\n",
      "Starting tokenizing...\n",
      "Starting lemmatizing and filtering...\n",
      "Took 11619 seconds to clean texts\n"
     ]
    }
   ],
   "source": [
    "data = data.loc[data['word_count'] > 199,:]\n",
    "data = data.loc[data['word_count'] < 701,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_articles = cleanData(data,'content')\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "      <td>694</td>\n",
       "      <td>seoul south korea north korea s leader kim sai...</td>\n",
       "      <td>[seoul, south, korea, north, korea, leader, ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taiwan’s President Accuses China of Renewed In...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>BEIJING  —   President Tsai   of Taiwan sharpl...</td>\n",
       "      <td>571</td>\n",
       "      <td>beijing president tsai of taiwan sharply criti...</td>\n",
       "      <td>[beijing, president, tsai, taiwan, sharply, cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to form healthy habits in your 20s - The N...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>This article is part of a series aimed at help...</td>\n",
       "      <td>665</td>\n",
       "      <td>this article is part of a series aimed at help...</td>\n",
       "      <td>[article, part, series, aimed, helping, naviga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     publication  \\\n",
       "0  Kim Jong-un Says North Korea Is Preparing to T...  New York Times   \n",
       "1  Taiwan’s President Accuses China of Renewed In...  New York Times   \n",
       "2  How to form healthy habits in your 20s - The N...  New York Times   \n",
       "\n",
       "                                             content  word_count  \\\n",
       "0  SEOUL, South Korea  —   North Korea’s leader, ...         694   \n",
       "1  BEIJING  —   President Tsai   of Taiwan sharpl...         571   \n",
       "2  This article is part of a series aimed at help...         665   \n",
       "\n",
       "                                     cleaned_content  \\\n",
       "0  seoul south korea north korea s leader kim sai...   \n",
       "1  beijing president tsai of taiwan sharply criti...   \n",
       "2  this article is part of a series aimed at help...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [seoul, south, korea, north, korea, leader, ki...  \n",
       "1  [beijing, president, tsai, taiwan, sharply, cr...  \n",
       "2  [article, part, series, aimed, helping, naviga...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_articles.iloc[:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bigrams to articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams, complete_data = addBigrams(clean_articles, 'tokens')\n",
    "del(clean_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code recognizes sets of consecutive words that are in our dataset at least 250 articles. These couples are returned as one word separated by a hyphen, as illustrated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new_york', 'north_korea', 'new', 'haven']\n"
     ]
    }
   ],
   "source": [
    "print(bigrams['new','york','north','korea', 'not','a','bigram'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bag of words representation for articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, dictionary = createBOW(complete_data, 'tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready to train the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chinese City Official Shoots 2 Others and Kill...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>BEIJING  —   A city official in southwest Chin...</td>\n",
       "      <td>358</td>\n",
       "      <td>beijing a city official in southwest china unl...</td>\n",
       "      <td>[beijing, city, official, southwest, china, un...</td>\n",
       "      <td>[(11, 1), (16, 1), (54, 2), (73, 1), (79, 4), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ivanka Trump’s New Washington Home Once Belong...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>WASHINGTON  —   Ivanka Trump, who is weighing ...</td>\n",
       "      <td>683</td>\n",
       "      <td>washington ivanka trump who is weighing a prom...</td>\n",
       "      <td>[washington, ivanka, trump, weighing, prominen...</td>\n",
       "      <td>[(51, 1), (55, 3), (60, 1), (69, 1), (71, 1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How We Put Together Our 52 Places to Go List -...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>For the 12th straight year, the Travel section...</td>\n",
       "      <td>567</td>\n",
       "      <td>for the th straight year the travel section pr...</td>\n",
       "      <td>[th, straight, year, travel, section, present,...</td>\n",
       "      <td>[(38, 2), (60, 1), (84, 1), (108, 1), (161, 1)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title     publication  \\\n",
       "10  Chinese City Official Shoots 2 Others and Kill...  New York Times   \n",
       "11  Ivanka Trump’s New Washington Home Once Belong...  New York Times   \n",
       "12  How We Put Together Our 52 Places to Go List -...  New York Times   \n",
       "\n",
       "                                              content  word_count  \\\n",
       "10  BEIJING  —   A city official in southwest Chin...         358   \n",
       "11  WASHINGTON  —   Ivanka Trump, who is weighing ...         683   \n",
       "12  For the 12th straight year, the Travel section...         567   \n",
       "\n",
       "                                      cleaned_content  \\\n",
       "10  beijing a city official in southwest china unl...   \n",
       "11  washington ivanka trump who is weighing a prom...   \n",
       "12  for the th straight year the travel section pr...   \n",
       "\n",
       "                                               tokens  \\\n",
       "10  [beijing, city, official, southwest, china, un...   \n",
       "11  [washington, ivanka, trump, weighing, prominen...   \n",
       "12  [th, straight, year, travel, section, present,...   \n",
       "\n",
       "                                                  bow  \n",
       "10  [(11, 1), (16, 1), (54, 2), (73, 1), (79, 4), ...  \n",
       "11  [(51, 1), (55, 3), (60, 1), (69, 1), (71, 1), ...  \n",
       "12  [(38, 2), (60, 1), (84, 1), (108, 1), (161, 1)...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.iloc[10:13,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><br> LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that our dictionary is filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'associate'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training data has 8096 distinct words\n",
      "Our corpus has 69934 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"Our training data has {} distinct words\".format(len(dictionary)))\n",
    "print(\"Our corpus has {} documents\".format(len(training_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for LDA model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = dictionary.id2token   # Dictionary with BOW token definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics = 20    # This number of topics led to the most interpretable topics\n",
    "chunksize = 9000\n",
    "passes = 15\n",
    "iterations = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 5416.5155465602875 seconds to train model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "start = time.time()\n",
    "model = LdaModel(corpus = training_data['bow'], num_topics = num_topics, id2word = id2word, chunksize = chunksize, iterations = iterations, passes = passes)\n",
    "print(\"Took {} seconds to train model\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print resulting topics. As assumed in our model, our articles can be composed of 20 different topics. These topics are generated by the following word distributions, which are easily interpretable. The first topic, for example, is the judiciary. The second one is foreign conflicts, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022*\"state\" + 0.020*\"court\" + 0.018*\"law\" + 0.013*\"federal\" + 0.009*\"new\" + 0.009*\"case\" + 0.008*\"judge\" + 0.008*\"right\" + 0.008*\"government\" + 0.008*\"order\" + 0.007*\"justice\" + 0.007*\"would\" + 0.007*\"rule\" + 0.007*\"department\" + 0.006*\"decision\" + 0.006*\"legal\" + 0.005*\"public\" + 0.005*\"ban\" + 0.005*\"lawsuit\" + 0.005*\"executive\" + 0.004*\"attorney\" + 0.004*\"supreme\" + 0.004*\"statement\" + 0.004*\"supreme_court\" + 0.004*\"district\" + 0.004*\"appeal\" + 0.004*\"use\" + 0.004*\"governor\" + 0.004*\"administration\" + 0.004*\"ruling\"\n",
      "\n",
      "0.014*\"state\" + 0.010*\"military\" + 0.009*\"attack\" + 0.008*\"force\" + 0.008*\"syria\" + 0.007*\"islamic\" + 0.007*\"north\" + 0.007*\"war\" + 0.007*\"korea\" + 0.006*\"united\" + 0.006*\"government\" + 0.006*\"group\" + 0.006*\"iran\" + 0.006*\"country\" + 0.006*\"syrian\" + 0.005*\"islamic_state\" + 0.005*\"official\" + 0.005*\"nuclear\" + 0.005*\"security\" + 0.005*\"isi\" + 0.005*\"u\" + 0.005*\"russia\" + 0.005*\"north_korea\" + 0.005*\"united_state\" + 0.004*\"iraq\" + 0.004*\"missile\" + 0.004*\"south\" + 0.004*\"also\" + 0.004*\"president\" + 0.004*\"israel\"\n",
      "\n",
      "0.035*\"woman\" + 0.011*\"child\" + 0.010*\"year\" + 0.010*\"case\" + 0.009*\"men\" + 0.009*\"court\" + 0.009*\"sexual\" + 0.008*\"charge\" + 0.008*\"prison\" + 0.007*\"girl\" + 0.007*\"trial\" + 0.007*\"sex\" + 0.006*\"told\" + 0.006*\"prosecutor\" + 0.006*\"family\" + 0.006*\"also\" + 0.005*\"according\" + 0.005*\"former\" + 0.005*\"judge\" + 0.005*\"lawyer\" + 0.005*\"attorney\" + 0.005*\"assault\" + 0.005*\"victim\" + 0.004*\"two\" + 0.004*\"female\" + 0.004*\"accused\" + 0.004*\"time\" + 0.004*\"sentence\" + 0.004*\"one\" + 0.004*\"crime\"\n",
      "\n",
      "0.016*\"say\" + 0.015*\"people\" + 0.013*\"like\" + 0.011*\"one\" + 0.009*\"think\" + 0.008*\"get\" + 0.008*\"would\" + 0.008*\"even\" + 0.008*\"thing\" + 0.008*\"know\" + 0.008*\"make\" + 0.007*\"way\" + 0.007*\"want\" + 0.007*\"going\" + 0.006*\"time\" + 0.005*\"many\" + 0.005*\"much\" + 0.005*\"really\" + 0.005*\"u\" + 0.005*\"right\" + 0.005*\"go\" + 0.005*\"see\" + 0.005*\"good\" + 0.005*\"something\" + 0.004*\"need\" + 0.004*\"could\" + 0.004*\"american\" + 0.004*\"lot\" + 0.004*\"work\" + 0.004*\"take\"\n",
      "\n",
      "0.009*\"say\" + 0.008*\"year\" + 0.008*\"study\" + 0.007*\"health\" + 0.007*\"water\" + 0.006*\"new\" + 0.006*\"found\" + 0.005*\"also\" + 0.005*\"food\" + 0.005*\"people\" + 0.005*\"one\" + 0.005*\"could\" + 0.004*\"research\" + 0.004*\"researcher\" + 0.004*\"drug\" + 0.004*\"state\" + 0.004*\"time\" + 0.004*\"scientist\" + 0.004*\"disease\" + 0.004*\"human\" + 0.004*\"according\" + 0.004*\"may\" + 0.004*\"university\" + 0.004*\"medical\" + 0.003*\"patient\" + 0.003*\"doctor\" + 0.003*\"zika\" + 0.003*\"animal\" + 0.003*\"center\" + 0.003*\"national\"\n",
      "\n",
      "0.032*\"gun\" + 0.020*\"senate\" + 0.016*\"court\" + 0.013*\"supreme\" + 0.013*\"supreme_court\" + 0.010*\"nominee\" + 0.008*\"justice\" + 0.008*\"space\" + 0.008*\"senator\" + 0.008*\"would\" + 0.008*\"scalia\" + 0.008*\"obama\" + 0.007*\"president\" + 0.007*\"democrat\" + 0.007*\"gorsuch\" + 0.007*\"pipeline\" + 0.007*\"control\" + 0.007*\"american\" + 0.007*\"confirmation\" + 0.007*\"nomination\" + 0.007*\"biden\" + 0.007*\"second\" + 0.006*\"dakota\" + 0.006*\"amendment\" + 0.006*\"garland\" + 0.006*\"republican\" + 0.006*\"nasa\" + 0.005*\"check\" + 0.005*\"agreed_buy\" + 0.005*\"vote\"\n",
      "\n",
      "0.101*\"trump\" + 0.037*\"president\" + 0.020*\"obama\" + 0.019*\"donald\" + 0.016*\"white\" + 0.014*\"house\" + 0.013*\"white_house\" + 0.012*\"donald_trump\" + 0.008*\"washington\" + 0.008*\"administration\" + 0.007*\"mr\" + 0.007*\"campaign\" + 0.005*\"would\" + 0.005*\"first\" + 0.005*\"press\" + 0.005*\"told\" + 0.005*\"presidential\" + 0.004*\"american\" + 0.004*\"time\" + 0.004*\"former\" + 0.004*\"office\" + 0.004*\"policy\" + 0.004*\"comment\" + 0.004*\"mr_trump\" + 0.004*\"post\" + 0.004*\"penny\" + 0.004*\"also\" + 0.004*\"day\" + 0.003*\"country\" + 0.003*\"barack\"\n",
      "\n",
      "0.010*\"new\" + 0.009*\"year\" + 0.008*\"show\" + 0.007*\"one\" + 0.006*\"first\" + 0.005*\"time\" + 0.005*\"film\" + 0.005*\"like\" + 0.005*\"also\" + 0.004*\"star\" + 0.004*\"day\" + 0.004*\"life\" + 0.004*\"music\" + 0.004*\"say\" + 0.004*\"movie\" + 0.003*\"york\" + 0.003*\"family\" + 0.003*\"two\" + 0.003*\"new_york\" + 0.003*\"love\" + 0.003*\"world\" + 0.003*\"book\" + 0.003*\"song\" + 0.003*\"home\" + 0.003*\"photo\" + 0.003*\"night\" + 0.003*\"story\" + 0.003*\"work\" + 0.003*\"last\" + 0.003*\"series\"\n",
      "\n",
      "0.015*\"china\" + 0.011*\"oil\" + 0.010*\"economy\" + 0.010*\"trade\" + 0.009*\"job\" + 0.009*\"economic\" + 0.009*\"would\" + 0.008*\"state\" + 0.007*\"energy\" + 0.007*\"editing\" + 0.007*\"worker\" + 0.007*\"country\" + 0.007*\"united\" + 0.007*\"policy\" + 0.007*\"global\" + 0.007*\"agreement\" + 0.007*\"government\" + 0.006*\"deal\" + 0.006*\"world\" + 0.006*\"chinese\" + 0.006*\"united_state\" + 0.005*\"year\" + 0.005*\"japan\" + 0.005*\"bank\" + 0.005*\"president\" + 0.005*\"new\" + 0.005*\"labor\" + 0.005*\"reporting\" + 0.005*\"climate\" + 0.004*\"change\"\n",
      "\n",
      "0.030*\"percent\" + 0.012*\"year\" + 0.012*\"company\" + 0.010*\"new\" + 0.010*\"market\" + 0.008*\"rate\" + 0.007*\"data\" + 0.007*\"price\" + 0.007*\"last\" + 0.006*\"apple\" + 0.005*\"technology\" + 0.005*\"month\" + 0.005*\"car\" + 0.005*\"stock\" + 0.005*\"share\" + 0.004*\"week\" + 0.004*\"also\" + 0.004*\"fell\" + 0.004*\"since\" + 0.004*\"fed\" + 0.004*\"high\" + 0.004*\"analyst\" + 0.004*\"sale\" + 0.004*\"google\" + 0.004*\"average\" + 0.004*\"first\" + 0.004*\"quarter\" + 0.004*\"according\" + 0.004*\"growth\" + 0.004*\"wednesday\"\n",
      "\n",
      "0.017*\"mexico\" + 0.017*\"immigration\" + 0.017*\"border\" + 0.013*\"immigrant\" + 0.013*\"refugee\" + 0.013*\"san\" + 0.013*\"country\" + 0.013*\"mexican\" + 0.012*\"state\" + 0.011*\"texas\" + 0.010*\"city\" + 0.009*\"illegal\" + 0.007*\"drug\" + 0.007*\"united\" + 0.007*\"security\" + 0.007*\"wall\" + 0.006*\"united_state\" + 0.006*\"california\" + 0.006*\"people\" + 0.005*\"los\" + 0.005*\"year\" + 0.005*\"crime\" + 0.005*\"francisco\" + 0.005*\"enforcement\" + 0.005*\"official\" + 0.005*\"migrant\" + 0.005*\"san_francisco\" + 0.005*\"visa\" + 0.005*\"nieto\" + 0.005*\"muslim\"\n",
      "\n",
      "0.020*\"republican\" + 0.018*\"house\" + 0.017*\"bill\" + 0.017*\"tax\" + 0.017*\"would\" + 0.012*\"health\" + 0.011*\"congress\" + 0.011*\"plan\" + 0.010*\"care\" + 0.009*\"senate\" + 0.008*\"ryan\" + 0.008*\"democrat\" + 0.008*\"obamacare\" + 0.007*\"budget\" + 0.006*\"insurance\" + 0.006*\"legislation\" + 0.006*\"state\" + 0.006*\"program\" + 0.006*\"government\" + 0.005*\"people\" + 0.005*\"vote\" + 0.005*\"health_care\" + 0.005*\"american\" + 0.005*\"year\" + 0.005*\"president\" + 0.005*\"spending\" + 0.005*\"act\" + 0.005*\"lawmaker\" + 0.004*\"federal\" + 0.004*\"repeal\"\n",
      "\n",
      "0.019*\"game\" + 0.013*\"team\" + 0.009*\"year\" + 0.009*\"season\" + 0.008*\"player\" + 0.008*\"first\" + 0.007*\"last\" + 0.006*\"time\" + 0.006*\"two\" + 0.006*\"one\" + 0.005*\"play\" + 0.005*\"sport\" + 0.005*\"back\" + 0.005*\"win\" + 0.005*\"second\" + 0.004*\"league\" + 0.004*\"three\" + 0.004*\"get\" + 0.004*\"would\" + 0.004*\"day\" + 0.004*\"coach\" + 0.004*\"going\" + 0.004*\"football\" + 0.004*\"point\" + 0.003*\"nfl\" + 0.003*\"week\" + 0.003*\"final\" + 0.003*\"world\" + 0.003*\"fan\" + 0.003*\"run\"\n",
      "\n",
      "0.016*\"student\" + 0.015*\"school\" + 0.009*\"country\" + 0.008*\"party\" + 0.008*\"european\" + 0.008*\"minister\" + 0.007*\"government\" + 0.007*\"university\" + 0.007*\"year\" + 0.007*\"britain\" + 0.007*\"political\" + 0.006*\"leader\" + 0.006*\"union\" + 0.006*\"president\" + 0.005*\"eu\" + 0.005*\"people\" + 0.005*\"group\" + 0.005*\"may\" + 0.005*\"college\" + 0.005*\"protest\" + 0.005*\"prime\" + 0.005*\"would\" + 0.005*\"british\" + 0.005*\"europe\" + 0.005*\"vote\" + 0.005*\"germany\" + 0.005*\"member\" + 0.005*\"education\" + 0.004*\"also\" + 0.004*\"election\"\n",
      "\n",
      "0.012*\"investigation\" + 0.012*\"clinton\" + 0.012*\"email\" + 0.012*\"russian\" + 0.011*\"fbi\" + 0.010*\"russia\" + 0.009*\"official\" + 0.009*\"committee\" + 0.009*\"information\" + 0.009*\"department\" + 0.009*\"intelligence\" + 0.008*\"comey\" + 0.008*\"security\" + 0.008*\"report\" + 0.006*\"director\" + 0.006*\"state\" + 0.006*\"former\" + 0.006*\"agency\" + 0.005*\"government\" + 0.005*\"campaign\" + 0.005*\"national\" + 0.005*\"election\" + 0.005*\"document\" + 0.005*\"general\" + 0.004*\"secretary\" + 0.004*\"flynn\" + 0.004*\"would\" + 0.004*\"told\" + 0.004*\"also\" + 0.004*\"house\"\n",
      "\n",
      "0.030*\"clinton\" + 0.029*\"trump\" + 0.018*\"republican\" + 0.015*\"campaign\" + 0.013*\"candidate\" + 0.012*\"election\" + 0.012*\"hillary\" + 0.011*\"state\" + 0.011*\"voter\" + 0.011*\"presidential\" + 0.010*\"party\" + 0.010*\"vote\" + 0.009*\"hillary_clinton\" + 0.009*\"sander\" + 0.009*\"democratic\" + 0.009*\"cruz\" + 0.009*\"donald\" + 0.008*\"donald_trump\" + 0.007*\"poll\" + 0.007*\"percent\" + 0.006*\"new\" + 0.006*\"nominee\" + 0.006*\"primary\" + 0.006*\"democrat\" + 0.005*\"debate\" + 0.005*\"win\" + 0.005*\"gop\" + 0.005*\"would\" + 0.005*\"support\" + 0.004*\"race\"\n",
      "\n",
      "0.030*\"police\" + 0.013*\"officer\" + 0.009*\"told\" + 0.007*\"city\" + 0.007*\"man\" + 0.007*\"shooting\" + 0.006*\"two\" + 0.006*\"one\" + 0.006*\"killed\" + 0.006*\"shot\" + 0.006*\"people\" + 0.006*\"death\" + 0.005*\"according\" + 0.005*\"family\" + 0.004*\"county\" + 0.004*\"incident\" + 0.004*\"authority\" + 0.004*\"video\" + 0.004*\"black\" + 0.004*\"car\" + 0.004*\"home\" + 0.004*\"police_officer\" + 0.004*\"department\" + 0.004*\"reported\" + 0.004*\"time\" + 0.004*\"attack\" + 0.004*\"suspect\" + 0.004*\"found\" + 0.003*\"day\" + 0.003*\"arrested\"\n",
      "\n",
      "0.027*\"company\" + 0.020*\"million\" + 0.018*\"billion\" + 0.011*\"bank\" + 0.010*\"deal\" + 0.009*\"business\" + 0.008*\"firm\" + 0.008*\"year\" + 0.007*\"inc\" + 0.007*\"would\" + 0.007*\"investor\" + 0.007*\"source\" + 0.007*\"financial\" + 0.007*\"fund\" + 0.007*\"wednesday\" + 0.007*\"share\" + 0.006*\"new\" + 0.006*\"money\" + 0.006*\"executive\" + 0.006*\"group\" + 0.005*\"investment\" + 0.005*\"sale\" + 0.005*\"according\" + 0.005*\"last\" + 0.005*\"pay\" + 0.005*\"two\" + 0.004*\"chief\" + 0.004*\"also\" + 0.004*\"market\" + 0.004*\"reporting\"\n",
      "\n",
      "0.026*\"news\" + 0.021*\"twitter\" + 0.018*\"medium\" + 0.015*\"facebook\" + 0.009*\"fox\" + 0.009*\"video\" + 0.009*\"social\" + 0.007*\"post\" + 0.007*\"social_medium\" + 0.007*\"breitbart\" + 0.006*\"ad\" + 0.006*\"network\" + 0.006*\"story\" + 0.006*\"show\" + 0.006*\"user\" + 0.006*\"time\" + 0.005*\"also\" + 0.005*\"follow\" + 0.005*\"pic\" + 0.005*\"new\" + 0.005*\"tweet\" + 0.005*\"account\" + 0.004*\"fox_news\" + 0.004*\"pic_twitter\" + 0.004*\"online\" + 0.004*\"page\" + 0.004*\"site\" + 0.004*\"posted\" + 0.004*\"comment\" + 0.004*\"wrote\"\n",
      "\n",
      "0.013*\"people\" + 0.010*\"flight\" + 0.009*\"city\" + 0.008*\"air\" + 0.008*\"attack\" + 0.007*\"plane\" + 0.007*\"airport\" + 0.007*\"one\" + 0.007*\"fire\" + 0.007*\"area\" + 0.006*\"official\" + 0.006*\"two\" + 0.006*\"passenger\" + 0.006*\"french\" + 0.005*\"mile\" + 0.005*\"day\" + 0.005*\"island\" + 0.005*\"station\" + 0.005*\"service\" + 0.005*\"hour\" + 0.005*\"building\" + 0.005*\"france\" + 0.004*\"according\" + 0.004*\"told\" + 0.004*\"coast\" + 0.004*\"town\" + 0.004*\"near\" + 0.004*\"train\" + 0.004*\"sunday\" + 0.004*\"le\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_topics):\n",
    "    print(model.print_topic(i,topn=30)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of our articles, compute its PDF over topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data['topics'] = training_data.bow.apply(lambda x: model.get_document_topics(x, minimum_probability = 1e-8))\n",
    "# get_document_topics returns tuples but we only want to keep the probs\n",
    "training_data['topics'] = [np.array([prob[1] for prob in row]) for row in training_data.topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bow</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2 Credit-Reporting Agencies Must Pay $23 Milli...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>The nation’s consumer watchdog agency on Tuesd...</td>\n",
       "      <td>340</td>\n",
       "      <td>the nation s consumer watchdog agency on tuesd...</td>\n",
       "      <td>[nation, consumer, watchdog, agency, tuesday, ...</td>\n",
       "      <td>[(47, 1), (324, 1), (490, 1), (502, 1), (585, ...</td>\n",
       "      <td>[0.269334122173, 0.000340136059492, 0.06643992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chase Sapphire Reserve Card’s Huge Bonus Will ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>When a Wall Street banking institution starts ...</td>\n",
       "      <td>365</td>\n",
       "      <td>when a wall street banking institution starts ...</td>\n",
       "      <td>[wall, street, banking, institution, start, th...</td>\n",
       "      <td>[(51, 2), (108, 1), (361, 1), (433, 1), (565, ...</td>\n",
       "      <td>[0.000270270275914, 0.000270270272897, 0.00027...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title     publication  \\\n",
       "18  2 Credit-Reporting Agencies Must Pay $23 Milli...  New York Times   \n",
       "19  Chase Sapphire Reserve Card’s Huge Bonus Will ...  New York Times   \n",
       "\n",
       "                                              content  word_count  \\\n",
       "18  The nation’s consumer watchdog agency on Tuesd...         340   \n",
       "19  When a Wall Street banking institution starts ...         365   \n",
       "\n",
       "                                      cleaned_content  \\\n",
       "18  the nation s consumer watchdog agency on tuesd...   \n",
       "19  when a wall street banking institution starts ...   \n",
       "\n",
       "                                               tokens  \\\n",
       "18  [nation, consumer, watchdog, agency, tuesday, ...   \n",
       "19  [wall, street, banking, institution, start, th...   \n",
       "\n",
       "                                                  bow  \\\n",
       "18  [(47, 1), (324, 1), (490, 1), (502, 1), (585, ...   \n",
       "19  [(51, 2), (108, 1), (361, 1), (433, 1), (565, ...   \n",
       "\n",
       "                                               topics  \n",
       "18  [0.269334122173, 0.000340136059492, 0.06643992...  \n",
       "19  [0.000270270275914, 0.000270270272897, 0.00027...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.iloc[18:20,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><br>Recommending further articles to readers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The code below returns the three most similar articles as assessed by our model. It uses functionality defined in the module notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an example. Pick a random text, say the 1112th one in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The veteran television personality Jane Pauley will replace Charles Osgood as the anchor of the highly rated CBS show “Sunday Morning. ” Mr. Osgood, who is retiring, announced the news on his last show on Sunday. Ms. Pauley’s first day in the role will be Oct. 9, and she will become only the third anchor of the show, which started in 1979. For Ms. Pauley, 65, a return to the anchor role for a morning television show represents an unexpected   comeback. And by selecting her instead of a younger    CBS is clearly trying to ease the transition from Mr. Osgood, 83, whose folksy delivery has been a mainstay on the show for more than two decades. In a statement, the president of CBS News, David Rhodes, said, “Charles Osgood is a television news legend  —   and so is Jane Pauley. ” Ms. Pauley first catapulted to fame at age 25 when she replaced Barbara Walters as an anchor of the “Today” show 40 years ago. She remained with “Today” through the late 1980s until the notoriously messy handoff in 1989, when Ms. Pauley left the show and was replaced by Deborah Norville. Ms. Pauley later was a host of NBC’s newsmagazine “Dateline” from 1992 to 2003. But for much of the next decade,   television opportunities dwindled for Ms. Pauley, though she had a daytime talk show that lasted a season and she made appearances on “Today. ” She became a CBS contributor two years ago and has filled in for Mr. Osgood on “Sunday Morning” and for Scott Pelley on the “CBS Evening News. ” She has reported stories for the Sunday morning show, including the only television interview with David Letterman in the   to his retirement last year. The transition is an important one for the network. “Sunday Morning” is a powerful ratings machine: It attracts nearly six million viewers and is by far the   Sunday morning news show. Its big viewership has helped the show that follows it, “Face the Nation,” remain the   Sunday morning public affairs show. (“Meet the Press” on NBC attracts the most viewers in the   to    bracket coveted by advertisers.) And this is the second consecutive year that CBS has had a peaceful Sunday morning handoff, something that can be rare for morning shows. (Recall the departures of Ms. Pauley or Ann Curry from “Today,” or David Gregory’s firing from “Meet the Press. ”) Last year, Bob Schieffer introduced John Dickerson on the air as the new anchor of “Face the Nation,” just as Mr. Osgood did with Ms. Pauley on Sunday. “Charles Osgood set the standard for ‘CBS Sunday Morning,’” Ms. Pauley said in a statement. “And it’s a great honor to be given the chance to further our show’s legacy of excellence. I look forward to bringing loyal viewers the kind of engaging, original reporting that has made the broadcast so irresistible for so long. ”'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article1 = round(np.random.randn()*len(training_data)\n",
    "training_data.iloc[article1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arnold Schwarzenegger’s debut as the new boss of NBC’s New Celebrity Apprentice drew soft ratings Monday night without its longtime host and current   Donald Trump. [The season premiere of Celebrity Apprentice drew an average of 4. 9 million viewers and a 1. 3 rating in the     demo, according to the Hollywood Reporter. The outlet notes those numbers are down a significant 35 percent from last year’s Donald   premiere of the show.  NBC did heavy promotion for the new Apprentice, with TV spots highlighting a     Schwarzenegger poised to take over the boss position played by Trump for 14 seasons. The network also teased Schwarzenegger’s replacement line for Trump’s “You’re fired” Schwarzenegger’s updated catchphrase, revealed on Monday night’s episode, is “You’re terminated. ” The show also drew some buzz when it was reported that Trump would retain his executive producer credit on the show (though he said he would not have any involvement in it whatsoever). Neither factor appeared to help the show in the ratings, however, as the 21st season premiere of ABC’s The Bachelor led all network programs Monday night with an average of 6. 6 million viewers and a 2. 2 rating in the key demo. The premiere of the   Apprentice  —   which features celebrity contestants including Boy George, Jon Lovitz, WNBA star Lisa Leslie and Jersey Shore alum Nicole “Snooki” Polizzi  —   drew mostly poor reviews. In his review of the   first episode, New York Times television critic Mike Hale wrote that Schwarzenegger’s “cautiousness and rigidity make him a poor fit” for the show. “With Mr. Schwarzenegger, there’s no joy, just a  —   you’ll pardon the word  —   robotic professionalism,” Hale wrote. “His rebukes don’t have enough bite, his stares don’t have enough menace. ” Meanwhile, the Washington Post‘s Hank Stuever wrote that the new show suffers from the “utterly rote fashion with which it is being conducted” and failed to take advantage of the opportunity to reinvent itself. The New Celebr\n",
      "\n",
      "\n",
      "Actress Amber Tamblyn bashed the creators of the naked,   Donald Trump statues that popped up in several U. S. cities in recent weeks. [“Body shaming is never OK, even when it comes to Trump,” the Sisterhood of the Traveling Pants star said in a brief Facebook post late Sunday.  “These statues aren’t art: They are a lazy, unoriginal concept, stolen mind you, from Ilma Gore’s painting which already made this exact same point earlier this year,” Tamblyn wrote.  In February, Los   artist Ilma Gore unveiled a humiliating painting of a nude Donald Trump. Not made it down to see @illmagore’s trump masterpiece yet? It’s here until 22nd April so add it to your diary. pic. twitter.   —   Maddox Gallery (@MaddoxGallery) April 14, 2016,  Last week,   statues of Trump popped up in Los Angeles, San Francisco, Cleveland, New York City, and Seattle. A group named Indecline, founded by Bum Fights creators Ryan MacPherson and Daniel Tanner, have claimed credit for the unflattering Trump sculptures, titled “The Emperor Has No Balls. ” “Like it or not, Trump is a    figure in world culture at the moment,” an Indecline spokesperson told the Washington Post Friday. The group approached a Las Vegas sculptor named Ginder, who happily took on the project. “When the guys from [Indecline] approached me, it was all because of my   abilities,” he told the Post. “Trump is just yet another monster, so it was absolutely in my wheelhouse to be able to create these monstrosities. ” However, Tamblyn says there’s nothing creative about the statues. “This is wholly unoriginal and uncreative,” the actress said.   Follow Jerome Hudson on Twitter: @JeromeEHudson\n",
      "\n",
      "\n",
      "The Radio City Rockettes will perform at   Donald Trump’s inauguration in Washington DC on January 20, the dance company announced Thursday. [The iconic dance troupe has performed at previous presidential inaugurations, including in 2001 and 2005, and will join previously announced performers the Mormon Tabernacle Choir and teenage opera singer Jackie Evancho at the event.  “The Radio City Rockettes, an original American brand, have performed at Radio City Music Hall since 1925 and, as treasured American icons, have taken part in some of the nation’s most illustrious events such as Super Bowl halftime shows, Macy’s Thanksgiving Day parades and presidential inaugurations, including in 2001 and 2005,” Madison Square Garden executive chairman James Dolan said in a statement. “We are honored that the Rockettes have again been asked to perform in the upcoming inauguration festivities,” he added. The announcement Thursday came as much speculation has centered on who would perform at Trump’s inauguration. Other names that had been floated for the gig included Andrea Bocelli, Garth Brooks and, most recently, the Beach Boys. The announcement of the Rockettes as Inauguration Day performers almost immediately prompted backlash against the dance troupe on social media, with some vowing to boycott the group altogether. I say no.  Boycott the   @Rockettes #BoycottRockettes,  —   The Toucan (@etotoucan) December 22, 2016,  @Rockettes Please, it can’t be true that you would perform at Trump’s inauguration.  Will you let him inspect every performer first?  —   Gary Delemeester (@gmdelemeester) December 22, 2016,  I will never go to see the Rockettes again👎 https:  .   —   Jackie BonnerFarnham (@JackieFarnham) December 22, 2016,  The Rockettes perform annually at New York City’s Radio City Music Hall. Trump will become the first President from New York since Franklin Delano Roosevelt was sworn in in 1933.   Follow Daniel Nussbaum on Twitter: @dznussbaum\n"
     ]
    }
   ],
   "source": [
    "similar1, similar2, similar3 = similarArticle(article1)\n",
    "print(training_data.iloc[similar1,2][:2000])\n",
    "print('\\n')\n",
    "print(training_data.iloc[similar2,2][:2000])\n",
    "print('\\n')\n",
    "print(training_data.iloc[similar3,2][:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Nice! The algorithm returns articles about pop culture that reference Trump. Let's try another one.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Wall Street Journal’s Potomac Watch columnist Kimberley Strassel details the “devastating case against a Clinton presidency” that can be made by reviewing the WikiLeaks documents combined with what is already known in the public record. Strassel notes that although “the nation now has proof of pretty much everything [Hillary Clinton] has been accused of,” the media “has almost uniformly ignored the flurry of bombshells, preferring to devote its front pages” to the story that Donald Trump “made lewd remarks a decade ago and now stands accused of groping women. ”[ From Strassel in the Wall Street Journal:  The Obama administration —  the federal government, supported by tax dollars —  was working as an extension of the Clinton campaign. The State Department coordinated with her staff in responding to the email scandal, and the Justice Department kept her team informed about developments in the court case. Worse, Mrs. Clinton’s State Department, as documents obtained under the Freedom of Information Act show, took special care of donors to the Clinton Foundation. In a series of 2010 emails, a senior aide to Mrs. Clinton asked a foundation official to let her know which groups offering assistance with the Haitian earthquake relief were “FOB” (Friends of Bill) or “WJC VIPs” (William Jefferson Clinton VIPs). Those who made the cut appear to have been teed up for contracts. Those who weren’t? Routed to a standard government website. The leaks show that the foundation was indeed the nexus of influence and money. The head of the Clinton Health Access Initiative, Ira Magaziner, suggested in a 2011 email that Bill Clinton call Sheikh Mohammed of Saudi Arabia to thank him for offering the use of a plane. In response, a top Clinton Foundation official wrote: “Unless Sheikh Mo has sent us a $6 million check, this sounds crazy to do. ”   …     The leaks also show that the press is in Mrs. Clinton’s pocket. Donna Brazile, a former Clinton staffer and a TV pundit, sent the exact wording of a coming CNN town hall question to the campaign in advance of the event. Other media allowed the Clinton camp to veto which quotes they used from interviews, worked to maximize her press events and offered campaign advice. Read the rest here. '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article2 = round(np.random.randn()*len(training_data)\n",
    "training_data.iloc[article2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democratic presidential nominee Hillary Clinton told Fox News’ Chris Wallace that she is “really proud” of her family’s charity the Clinton Foundation  —   after spending the past week hiding its existence from viewers of the Democratic National Convention. [The glaring contradiction prompted a video comparison, which you can watch above.  Wallace, in an exclusive   interview, asked Clinton about allegations first made in Clinton Cash, the book and now   novel, that Clinton used the    charity for international “  ” deals while she served as Secretary of State. Author and Breitbart News Senior    Peter Schweizer says that Clinton Foundation donors were on the receiving end of corrupt deals approved by Hillary’s State Department  —   including the sale of U. S. uranium to Russia and a rare, lucrative mining permit in Haiti. Clinton retorted that she is “really proud of the Clinton Foundation,” yet not a single speaker at the DNC last week  —   not even Bill or Chelsea Clinton  —   mentioned the Foundation or its spinoffs such as the Clinton Global Initiative. A dramatic documentary clip on Hillary’s record of service, narrated by acclaimed actor Morgan Freeman, failed to mention the Clinton Foundation or its work around the world. The omission left the clip feeling oddly scant, as only two   appeared on camera with stories to praise Clinton’s record from over 40 years in political life.  This week, news broke that the IRS is investigating the Clinton Foundation. Earlier this month, FBI Director James Comey would not confirm or deny whether the bureau is investigating the Foundation during congressional testimony. Just days later, The Globe and Mail reported that “The Canadian affiliate of the Clinton Foundation is spending an astounding 78 percent of the money it raises on administrative costs. ” Read the transcript of Wallace and Clinton’s exchange: WALLACE:  Let’s talk about the Clinton Foundation and allegations of    the argument, the allegation that foreign comp\n",
      "\n",
      "\n",
      "Clinton has said if she is elected president, the controversial family foundation will cease taking foreign donations, but other media outlets, including the Boston Globe and the liberal Huffington Post, have called for it to be shut down altogether. Speaking to campaign manager Robby Mook, Stephanopoulos wondered if the   pledge was not tantamount to admitting Clinton was wrong to take previous donations. “You announced this week that the foundation would no longer take contributions from foreign governments or corporations, if Secretary Clinton wins the White House,” Stephanopoulos stated, before asking, “Doesn’t it suggest that taking those contributions when Secretary Clinton was serving as secretary of state was wrong?” Stephanopoulos was communications director for the 1992 presidential campaign of Bill Clinton, then served as White House communications director and senior adviser for policy and strategy before leaving following Clinton’s first term. On Sunday, Stephanopoulos did not mention that records show he has personally donated $75, 000 to the foundation, noted NewsBusters. But he wasn’t finished putting the heat on Mook, who defended his boss by citing some of the positive work the foundation purports to have done. “The Clinton Foundation is clearly a liability for Hillary Clinton as she seeks the presidency,” Stephanopoulos said, quoting a recent Globe editorial. The foundation should remove a political and actual distraction and stop accepting funding. If Clinton is elected, the foundation should be shut down. ” Critics say the foundation’s receipt of contributions from foreign people and entities seeking business deals with the U. S. while Clinton served as secretary of state created the appearance of “pay to play. ” Stephanopoulos donated $25, 000 annually in 2012, 2013 and 2014, the foundation’s records show. He did not disclose the contributions to viewers, even when interviewing “Clinton Cash” author Peter Schweizer, whose book blew the lid off \n",
      "\n",
      "\n",
      "On Friday’s Breitbart News Daily, author Ed Klein said all of Hillary Clinton’s top confidantes may face jail time because of Clinton’s email scandal and are distancing themselves from the Clinton campaign because they do not want to damage her chances of winning the White House.  Klein told host and Breitbart News Executive Chairman Stephen K. Bannon that three of Clinton’s closest advisers —  Huma Abedin, Cheryl Mills, and Jake Sullivan —  have all been notified that they are going to be interviewed about the email scandal. Klein said what the FBI is after is “somebody to turn on Hillary and blab in order to save their own skin” and Sullivan, who has not been with Clinton as long as Abedin and Mills, is the “weakest link in the chain. ” Sullivan was one of Clinton’s top foreign policy advisers at the State Department, He said that all three have “lawyered up and are beginning to distance themselves from the campaign for fear that any connection to the email scandal could hurt Hillary’s chances at the nomination. ” The Clinton biographer pointed out that Mills, a Clinton loyalist for at least 25 years, defended President Bill Clinton against impeachment on the Senate floor and Abedin is like a second daughter to her and may actually be closer to Clinton than Chelsea. According to Klein, all three face “possible prison time” and “if the FBI can flip Jake Sullivan, Hillary may be in trouble” Klein said that according to his sources, there is no question that the FBI is all “on the same page and want to get to the bottom of this. ” He said FBI Director James Comey holds meetings in his own office with the prosectors in the Justice Department as the investigation is continuing. Comey, whom Klein referred to as the “Eliot Ness of our time,” is reportedly telling people that the “upshot of this investigation  …    . will be my legacy in history” and “he wants to get this right. ” But, according to Klein, there is “debate and dissension” in the Justice Department, where C\n"
     ]
    }
   ],
   "source": [
    "similar1, similar2, similar3 = similarArticle(article2)\n",
    "print(training_data.iloc[similar1,2][:2000])\n",
    "print('\\n')\n",
    "print(training_data.iloc[similar2,2][:2000])\n",
    "print('\\n')\n",
    "print(training_data.iloc[similar3,2][:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the LDA model, the recommendation process is very quick and doesn't take more than a few seconds to run"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
